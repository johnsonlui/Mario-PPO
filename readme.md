# Reinforcement Learning (Mario World 1-1)

![Image](https://i.imgur.com/NxLyjpj.png)
Demo Video: [Here](https://www.linkedin.com/feed/update/urn:li:ugcPost:6464759974051577856/)

# Run the code
Training:
```sh
$ python main.py
```
Testing:
```sh
$ python main_play.py
```

# Comments
During the development, again, reward shaping is necessary to let your agent to fulfill your target
On the other hand, found that entropy bonus is very important in the loss calculation in order to let your agent to keep exploration 
It is really a fruitful experience from this mini project ;)